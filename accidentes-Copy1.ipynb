{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkContext created\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "app_name = \"bubbly\"\n",
    "master = \"local[*]\"\n",
    "spark = (SparkSession.builder\n",
    "    .master(master)\n",
    "    .config(\"spark.driver.cores\", 1)\n",
    "    .appName(app_name)\n",
    "    .getOrCreate() )\n",
    "sc = spark.sparkContext\n",
    "print ('SparkContext created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SparkContext' object has no attribute 'createDataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-160991f68bb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m'fecha'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'02/01/2019'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'distrito'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'moratalaz'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'les'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'HL'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m ]\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'SparkContext' object has no attribute 'createDataFrame'"
     ]
    }
   ],
   "source": [
    "d =[\n",
    "    {'fecha':'01/01/2019','distrito':'centro','id':'1','les':'HL'},\n",
    "    {'fecha':'01/01/2019','distrito':'centro','id':'1','les':'HG'},\n",
    "    {'fecha':'01/01/2019','distrito':'arganzuela','id':'1','les':'HL'},\n",
    "    {'fecha':'02/01/2019','distrito':'centro','id':'1','les':'HL'},\n",
    "    {'fecha':'02/01/2019','distrito':'centro','id':'1','les':'HL'},\n",
    "    {'fecha':'02/01/2019','distrito':'moratalaz','id':'1','les':'HL'}\n",
    "]\n",
    "df = spark.createDataFrame(d,schema=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as func\n",
    "\n",
    "# Reducimos las columnas que tenemos que utilizar mediante la Select\n",
    "# y aplicamos las funciones necesarias a los datos\n",
    "accRed=accidenteData.select(\n",
    "#        func.to_date(accidenteData.FECHA, 'dd/MM/yyyy HH:mm:ss').alias('fecha'), \\\n",
    "        func.to_date(accidenteData.FECHA, 'dd/MM/yyyy').alias('fecha'), \\\n",
    "        accidenteData.DISTRITO.alias('distrito'), \\\n",
    "        accidenteData[\"Nº PARTE\"].alias('idAccidente'), \\\n",
    "        func.substring(accidenteData.LESIVIDAD,1,2).alias('lesividad'), \\\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fecha: date (nullable = true)\n",
      " |-- distrito: string (nullable = true)\n",
      " |-- idAccidente: string (nullable = true)\n",
      " |-- lesividad: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Las columnas del Dataframe accRed quedan así\n",
    "accRed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las filas de las personas ilesas\n",
    "# Agrupamos por fecha, distrito, accidente y lesividad para contar \n",
    "# los registros y tener el total de afectados.\n",
    "accGrouped=accRed.filter(accRed.lesividad != \"IL\")\\\n",
    "                .groupBy('fecha','distrito','idAccidente','lesividad')\\\n",
    "                .agg(func.count('lesividad').alias('victimas'))\\\n",
    "                .sort ('fecha','distrito','idAccidente','lesividad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------+\n",
      "|fecha|count(lesividad)|\n",
      "+-----+----------------+\n",
      "| null|           30122|\n",
      "+-----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accRed.groupBy('fecha').agg( func.count('lesividad')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fecha: date (nullable = true)\n",
      " |-- distrito: string (nullable = true)\n",
      " |-- idAccidente: string (nullable = true)\n",
      " |-- lesividad: string (nullable = true)\n",
      " |-- victimas: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Las columnas del Dataframe accRed quedan así\n",
    "accGrouped.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Por comodidad para poder guardar todos los datos en un único fichero utilizamos la librería pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accGrouped.toPandas().to_csv('/home/ubuntu/Downloads/victimas_por_fecha_distrito_accidente_lesion.csv',sep=';')\n",
    "accGrouped.toPandas().to_csv('/home/jose/Descargas/victimas_por_fecha_distrito_accidente_lesion.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
